{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-centered Machine Learning Project:\n",
    "## <b> Explanation of locally-important features for Deep fake detection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install VGGFace for Keras\n",
    "%pip install git+https://github.com/rcmalli/keras-vggface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "# Library for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Library for image manipulation\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Library for data preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Library for Ground Truth Generation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Library for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Library for general purpose\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Library for deep learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# VGGFace (clone repository before running)\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Library for evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTION OF ZIP FILES\n",
    "\n",
    "# Local paths\n",
    "real_fake_img_pth = \"C:\\\\Users\\\\FDB\\\\Downloads\\\\dataset.zip\"\n",
    "\n",
    "# Extracting the zip files\n",
    "# IntraFace\n",
    "with zipfile.ZipFile(real_fake_img_pth, 'r') as zip_ref:\n",
    "    zip_ref.extractall('C:\\\\Users\\\\FDB\\\\Downloads\\\\dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# Local paths\n",
    "real_fake_path = \"C:\\\\Users\\\\FDB\\\\Downloads\\\\dataset\\\\real_vs_fake\\\\real-vs-fake\" # USE YOUR LOCAL PATH\n",
    "\n",
    "# Create a dataset of images\n",
    "def create_dataset(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "        \n",
    "    for file in os.listdir(os.path.join(path, 'fake')):\n",
    "        image = cv2.imread(os.path.join(path, 'fake', file))\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        images.append(image)\n",
    "        labels.append(0)\n",
    "\n",
    "    for file in os.listdir(os.path.join(path, 'real')):\n",
    "        image = cv2.imread(os.path.join(path, 'real', file))\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        images.append(image)\n",
    "        labels.append(1)\n",
    "\n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "train_set = create_dataset(os.path.join(real_fake_path, \"train\"))\n",
    "test_set = create_dataset(os.path.join(real_fake_path, \"test\"))\n",
    "val_set = create_dataset(os.path.join(real_fake_path, \"valid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the images\n",
    "train_set[0] = train_set[0] / 255\n",
    "test_set[0] = test_set[0] / 255\n",
    "val_set[0] = val_set[0] / 255\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, y_train = train_set[0], train_set[1]\n",
    "X_test, y_test = test_set[0], test_set[1]\n",
    "X_val, y_val = val_set[0], val_set[1]\n",
    "\n",
    "# Encoding the labels\n",
    "y_train = to_categorical(y_train, num_classes = 2)\n",
    "y_test = to_categorical(y_test, num_classes = 2)\n",
    "y_val = to_categorical(y_val, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m custom_vgg_model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m, loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy, val_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[39m# MODEL TRAINING\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m# Callbacks\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m reduce_lr \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Fitting the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "# VGG FACE MODEL (TO DO: REARRANGE THE MODEL INTO A FUNCTION)\n",
    "\n",
    "#custom parameters\n",
    "nb_class = 2\n",
    "hidden_dim = 512\n",
    "\n",
    "vgg_model = VGGFace(include_top=False, input_shape=(224, 224, 3), pooling='avg') # pooling: None, avg or max\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='sigmoid', name='fc8')(x)\n",
    "custom_vgg_model = Model(vgg_model.input, out)\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "custom_vgg_model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy, val_accuracy'])\n",
    "\n",
    "# MODEL TRAINING\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, min_delta=0.0001)\n",
    "\n",
    "# Fitting the model\n",
    "history = custom_vgg_model.fit(X_train, y_train, batch_size = 32, epochs = 100, validation_data = (X_val, y_val), callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc6 (Dense)                 (None, 512)               12845568  \n",
      "                                                                 \n",
      " fc7 (Dense)                 (None, 512)               262656    \n",
      "                                                                 \n",
      " fc8 (Dense)                 (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,823,938\n",
      "Trainable params: 13,109,250\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATION OF THE RESULTS\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION OF THE MODEL\n",
    "\n",
    "# Predictions\n",
    "predictions = custom_vgg_model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_set.classes, np.argmax(predictions, axis=-1))\n",
    "print(cm)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_set.classes, np.argmax(predictions, axis=-1), target_names = ['fake', 'real']))s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING THE MODEL\n",
    "\n",
    "# Local paths\n",
    "model_path = \"C:\\\\Users\\\\FDB\\\\Downloads\\\\model.h5\"\n",
    "\n",
    "# Saving the model\n",
    "custom_vgg_model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
